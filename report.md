## 论文调研情况

### 1. 基础理论

- **ReAct (ICLR 2023)**: 提出了 Reasoning + Acting 的范式，是 Agentic RAG 的理论基础，让大模型在检索前先“思考”，解决多步推理问题。
- **Self-RAG (2023)**: 引入了 `Reflection Tokens`（反思令牌），让模型自评“是否需要检索”、“检索内容是否相关”，提供了**按需检索**的思路。

###  2. 优化方法

2024-2025 年的新工作：

- **Agentic RAG (arXiv 2025, Singh et al.)**: 系统性综述了将 Agent 引入 RAG 的架构，指出多智能体协作（如 Router, Retriever, Grader）是提升准确率的关键。
- **CRAG (Corrective RAG, 2024)**: 提出了一种“纠错”机制，当检索质量差时，自动触发网络搜索或备用逻辑，这可以用于解决我们教务问答中“查不到”的问题。
- **Adaptive-RAG (NAACL 2024)**: 根据问题复杂度动态选择策略（复杂问题多步检索），
- **GraphRAG (Microsoft, 2024)**: 虽然效果好但太重，可以参考一些部门-职责的实体关系，不照搬其繁重的图构建过程。



##  毕业设计定题方案

### 1. 问题描述 

- **背景**：在校期间，学生会有大量重复性、碎片化的咨询需求，通常直接询问辅导员或学长。例如：“综合测评里社团活动加几分？”、“请假超过三天要找谁签字？”、“转专业需要什么条件？”。
- **痛点**：
	1. **辅导员负担重**：面临海量重复提问，回复效率低。
	2. **信息检索难**：答案散落在《学生手册》、《评奖评优细则》、《教务处通知》等 PDF 文档和复杂的表格中，学生很难通过关键词搜索直接找到准确条款。
- **现状**：现有的关键词搜索只能返回文档列表，无法精准回答“加分计算”或“流程步骤”等需要推理的问题。

### 2. 目标

- **总体目标**：构建一个**“面向高校学工场景的轻量化智能问答助手”**。
- **核心能力**：
	1. **精准问答**：能理解学生口语化提问，从手册和表格中提取精确答案（而非长篇大论）。
	2. **复杂推理**：能处理跨文档、跨表格的查询（如结合《校历》和《请假规定》回答具体日期问题）。

### 3. 输入和输出定义

- **输入 (Input)**：学生的自然语言查询，以及学生的会话上下文。
	- *Case A (事实类)*：“大三智育成绩占综测的比例是多少？”
	- *Case B (推理类)*：“我获得了省级‘挑战杯’金奖，能加多少综测分？属于哪一类加分？”
- **输出 (Output)**：
	- **直接答案**：“根据《2024版综测细则》，省级挑战杯金奖可加 **2分**，属于‘学科竞赛类’加分。”
	- **溯源凭证**：展示答案来源的文档片段或表格行截图（Reference），确保可信度。





## RAG -demo

---

### 1. 文件上传与知识库构建

####  全链路流程

```
┌─────────────────┐
│  用户上传文件    │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 1. 文件验证与去重                                          │
│    ├─ 验证文件扩展名                                       │
│    ├─ 计算文件 MD5 哈希值                                  │
│    └─ 检查数据库中是否已存在该文件（基于 MD5）               │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 2. 文件存储（MinIO 对象存储）                              │
│    ├─ Bucket: uploads                                   │
│    ├─ Object Path: uploads/{fileName}                   │
│    └─ 保留原始文件内容和类型                              │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 3. 元数据记录（MySQL）                                     │
│    ├─ fileMd5: 文件唯一标识                               │
│    ├─ fileName: 原始文件名                                │
│    ├─ totalSize: 文件大小                                 │
│    ├─ status: 1（已完成）                                 │
│    └─ mergedAt: 上传时间                                  │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 4. 文档解析（ParseService + Apache Tika）                 │
│    ├─ 使用 AutoDetectParser 自动识别文件类型              │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 5. 智能分块（基于 HanLP 分词）                             │
│    ├─ 使用 StandardTokenizer 进行中文分词                │
│    ├─ 保持语义完整性，按句子边界切分                       │
│    ├─ 每个分块包含：                                       │
│    │   ├─ fileMd5: 文件标识                               │
│    │   ├─ chunkId: 分块序号                               │
│    │   └─ textContent: 分块文本内容                       │
│    └─ 保存到 document_vector 表                          │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 6. 向量化（VectorizationService + 通义千问 API）          │
│    ├─ 从数据库加载所有文本分块                             │
│    ├─ 调用通义千问 text-embedding-v4 模型                │
│    │   ├─ 批量处理（默认批次大小可配置）                    │
│    │   ├─ 维度：2048（可配置）                             │
│    │   └─ 编码格式：float                                  │
│    └─ 生成对应的向量表示（2048 维浮点数数组）              │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 7. 索引到 Elasticsearch                                   │
│    ├─ 索引名称：knowledge_base                            │
│    ├─ 文档结构：                                           │
│    │   ├─ id: UUID                                        │
│    │   ├─ fileMd5: 文件标识                               │
│    │   ├─ chunkId: 分块 ID                                │
│    │   ├─ textContent: 文本内容（用于关键词搜索）          │
│    │   ├─ vector: float[2048]（用于向量检索）             │
│    │   └─ model: "text-embedding-v4"                     │
│    └─ 批量索引（BulkRequest）                             │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────┐
│  上传完成        │
│  返回文件信息    │
└─────────────────┘
```

####  技术细节

```java
// 基于 HanLP 分词的语义分块
splitTextIntoChunksWithSemantics() {
    1. 使用 StandardTokenizer 分词
    2. 按句子边界切分（保留完整句子）
    3. 控制每个分块大小在 chunkSize 附近
    4. 避免截断词语或句子
}
```


---

### 2. 混合检索

**kNN 又称为 k 最近邻算法，是一种 Machine Learning 算法，会使用临近度来将一个数据点与训练时所使用并已记住的一个数据集进行对比，从而做出预测。**这种基于实例的学习使 kNN 赢得了“惰性学习”的名称，并让人们能够使用此算法解决分类或回归问题。kNN 算法的工作原理是假设相似的数据点会彼此靠近，即物以类聚。

BM25 是 Elasticsearch 的默认搜索评分算法，它的核心任务是 判断文档和搜索关键词的相关性。可以把它想象成一个公平的裁判——不仅看关键词出现次数，还要看关键词的“含金量”，同时防止长文档作弊。

- 关键词在 当前文档 出现次数越多，得分越高。
- 关键词在 所有文档中越稀有（比如“量子计算机” vs “的”），含金量越高，得分越高。
- 惩罚长文档灌水 —— 比如“区块链”在 10 页的报告中出现 5 次，比在 100 页的教材中出现 5 次更可信。



并不是简单地把关键词检索和语义检索这两种方式“各自执行一次，然后把结果合并一下”。用的是 Elasticsearch 官方推荐的**“召回 + 重排序（Recall + Rescore）”两阶段策略**。

**第一阶段**，会通过向量检索先从知识库中“捞”出一个比较大的候选集，比如是 topK 的 30 倍。这个阶段的目标很明确，就是“求全”。不管搜索的内容标不标准、意思精不精准，只要语义上跟用户的问题相关，不放过任何一个潜在的好结果。

**第二阶段**，调用 Elasticsearch 的 rescore 机制。也就是说，我们不再对所有文档做关键词匹配，而只是对刚刚召回的那一批候选集，再做一次 BM25 的关键词打分。这个阶段的目标是“求准”了—— 那些跟用户关键词完全匹配的结果，或者说那些“说到点子上”的结果，会被调高排名。

这种“先召回、后重排”的方式，既利用了向量检索的广度，又利用了关键词检索的精度

权重调整这块也可以非常灵活，向量查询暂定为 0.2，重排序查询暂定为向量查询的 5 倍





#### 全链路流程

```
┌─────────────────┐
│  用户输入查询    │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 1. 查询向量化（EmbeddingClient）                          │
│    ├─ 调用通义千问 text-embedding-v4 API                 │
│    ├─ 将查询文本转换为 2048 维向量                        │
│    └─ 失败降级：如失败则仅使用文本匹配                     │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 2. Elasticsearch 混合检索                                 │
│    ┌───────────────────────────────────────────┐        │
│    │ 2.1 向量召回（kNN Search）                 │        │
│    │     ├─ 字段：vector                        │        │
│    │     ├─ k: topK × 30（扩大召回量）          │        │
│    │     ├─ numCandidates: topK × 30           │        │
│    │     └─ 基于余弦相似度排序                  │        │
│    └───────────────────────────────────────────┘        │
│                    ▼                                     │
│    ┌───────────────────────────────────────────┐        │
│    │ 2.2 关键词过滤（Match Query）              │        │
│    │     ├─ 字段：textContent                   │        │
│    │     ├─ 查询词：query                       │        │
│    │     └─ 仅保留包含关键词的结果              │        │
│    └───────────────────────────────────────────┘        │
│                    ▼                                     │
│    ┌───────────────────────────────────────────┐        │
│    │ 2.3 BM25 重排序（Rescore）                 │        │
│    │     ├─ 窗口大小：topK × 30                 │        │
│    │     ├─ 原始分数权重：0.2                   │        │
│    │     ├─ BM25 分数权重：1.0                  │        │
│    │     ├─ 操作符：AND（所有关键词必须匹配）   │        │
│    │     └─ 综合向量相似度 + 文本相关性         │        │
│    └───────────────────────────────────────────┘        │
│                    ▼                                     │
│    └─ 最终返回 topK 个结果                              │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 3. 结果后处理                                              │
│    ├─ 提取搜索结果（fileMd5, chunkId, text, score）      │
│    ├─ 根据 fileMd5 批量查询文件名                         │
│    └─ 补充 fileName 字段到每个结果                        │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────┐
│  返回搜索结果    │
│  List<SearchResult>│
└─────────────────┘
```



```
最终分数 = 向量相似度分数 × 0.2 + BM25文本分数 × 1.0
```



---

### 3. 智能对话

#### 全链路流程

```
┌─────────────────┐
│  用户发送消息    │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 1. 会话管理                                                │
│    ├─ 获取或创建会话 ID（基于 userId）                     │
│    │   └─ 每个用户对应一个唯一的 conversationId（UUID）    │
│    └─ 加载该会话的历史对话记录                             │
│        └─ 最多保留最近 20 条消息（防止上下文过长）         │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 2. 知识检索（调用混合检索服务）                            │
│    ├─ 输入：用户消息                                       │
│    ├─ topK: 5（检索最相关的 5 个文档片段）                 │
│    └─ 输出：List<SearchResult>                           │
│        └─ 每个结果包含：文本内容、来源文件、相关性分数     │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 3. 上下文构建                                              │
│    ├─ 将检索到的文档片段格式化为上下文字符串               │
│    ├─ 示例格式：                                           │
│    │   """                                                │
│    │   参考资料1: [来自 xxx.pdf]                          │
│    │   {文档内容}                                          │
│    │                                                      │
│    │   参考资料2: [来自 yyy.doc]                          │
│    │   {文档内容}                                          │
│    │   """                                                │
│    └─ 将上下文与用户问题、历史对话组合                     │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 4. AI 回复生成（DeepSeek API）                             │
│    ├─ 模型：deepseek-chat                                 │
│    ├─ 输入构建：                                           │
│    │   ├─ System Prompt: 指定 AI 角色和规则                │
│    │   ├─ 上下文：检索到的知识库内容                        │
│    │   ├─ 历史对话：保持对话连贯性                          │
│    │   └─ 用户消息：当前问题                                │             │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────────────┐
│ 5. 对话历史更新                                            │
│    ├─ 保存用户消息到历史记录                               │
│    │   └─ {role: "user", content: message, timestamp}   │
│    ├─ 保存 AI 回复到历史记录                               │
│    │   └─ {role: "assistant", content: response, timestamp}│
│    └─ 自动清理：仅保留最近 20 条消息                       │
└────────┬────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────┐
│  返回 AI 回复    │
└─────────────────┘
```
